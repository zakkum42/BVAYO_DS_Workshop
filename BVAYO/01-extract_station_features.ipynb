{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Known Features From the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_fname = \"input/train_numeric.csv\"\n",
    "date_fname = \"input/train_date.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = pd.read_csv(numeric_fname, index_col=['Id'], nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.drop('Response', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.DataFrame(data=[f.split('_') for f in numeric_df.columns.tolist()], columns=['Line', 'Station', 'Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_features = {}\n",
    "for _, row in station_df.iterrows():\n",
    "    line_str = row['Line']\n",
    "    station_str = row['Station']\n",
    "    if (len(station_str) == 2): # if we have S0..S9\n",
    "        station_str = station_str.replace('S','S0') # Change it to S00..S09\n",
    "    station_id = line_str + station_str\n",
    "    l = []\n",
    "    if (station_id in station_features):\n",
    "        l = station_features.get(station_id)\n",
    "    l.append(row['Line']+'_'+row['Station']+'_'+row['Feature']) # Reconstruct feature names\n",
    "    station_features[station_id] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"dataset_features.py\", 'w')\n",
    "\n",
    "for station_id in sorted(station_features):\n",
    "    p_line = station_id + '_numeric' + ' = ' '[\\'' + '\\', \\''.join(station_features.get(station_id)) + '\\']' + '\\n'\n",
    "    fp.write(p_line)\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"dataset_features.py\", 'a')\n",
    "fp.write ('numeric_features = {\\n')\n",
    "\n",
    "for i, station_id in enumerate(sorted(station_features)):\n",
    "    p_line = ''\n",
    "    if (i % 5 == 0):\n",
    "        p_line = '\\t'\n",
    "    p_line = p_line + '\\'' + station_id + '\\': ' + station_id + '_numeric' + ', '\n",
    "    if (i % 5 == 4):\n",
    "        p_line = p_line + '\\n'\n",
    "    fp.write(p_line)\n",
    "\n",
    "fp.write('}\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.read_csv(date_fname, index_col=['Id'], nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.DataFrame(data=[f.split('_') for f in date_df.columns.tolist()], columns=['Line', 'Station', 'Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_features = {}\n",
    "for _, row in station_df.iterrows():\n",
    "    line_str = row['Line']\n",
    "    station_str = row['Station']\n",
    "    if (len(station_str) == 2): # if we have S0..S9\n",
    "        station_str = station_str.replace('S','S0') # Change it to S00..S09\n",
    "    station_id = line_str + station_str\n",
    "    l = []\n",
    "    if (station_id in station_features):\n",
    "        l = station_features.get(station_id)\n",
    "    l.append(row['Line']+'_'+row['Station']+'_'+row['Feature']) # Reconstruct feature names\n",
    "    station_features[station_id] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"dataset_features.py\", 'a')\n",
    "\n",
    "for station_id in sorted(station_features):\n",
    "    p_line = station_id + '_date' + ' = ' '[\\'' + '\\', \\''.join(station_features.get(station_id)) + '\\']' + '\\n'\n",
    "    fp.write(p_line)\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"dataset_features.py\", 'a')\n",
    "fp.write ('date_features = {\\n')\n",
    "\n",
    "for i, station_id in enumerate(sorted(station_features)):\n",
    "    p_line = ''\n",
    "    if (i % 5 == 0):\n",
    "        p_line = '\\t'\n",
    "    p_line = p_line + '\\'' + station_id + '\\': ' + station_id + '_date' + ', '\n",
    "    if (i % 5 == 4):\n",
    "        p_line = p_line + '\\n'\n",
    "    fp.write(p_line)\n",
    "\n",
    "fp.write('}\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features.L0S02_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
